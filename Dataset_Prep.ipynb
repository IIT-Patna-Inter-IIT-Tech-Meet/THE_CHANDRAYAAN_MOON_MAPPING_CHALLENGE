{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pds4_tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk9-ESM1wQAu",
        "outputId": "189858df-37cd-4540-bc06-97483653b81c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pds4_tools\n",
            "  Downloading pds4_tools-1.3-py2.py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pds4_tools) (1.21.6)\n",
            "Installing collected packages: pds4_tools\n",
            "Successfully installed pds4_tools-1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/ISRO_OHRC_Images/ch2_ohr_ncp_20200827T0619368134_d_img_d18.zip -d /content/drive/MyDrive/unzipped_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86DQwg5NF93B",
        "outputId": "b9e0895d-0232-43db-85cd-4d2f4083982a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/ISRO_OHRC_Images/ch2_ohr_ncp_20200827T0619368134_d_img_d18.zip\n",
            "   creating: /content/drive/MyDrive/unzipped_images/data/\n",
            "   creating: /content/drive/MyDrive/unzipped_images/data/calibrated/\n",
            "   creating: /content/drive/MyDrive/unzipped_images/data/calibrated/20200827/\n",
            "  inflating: /content/drive/MyDrive/unzipped_images/data/calibrated/20200827/ch2_ohr_ncp_20200827T0619368134_d_img_d18.xml  \n",
            "  inflating: /content/drive/MyDrive/unzipped_images/data/calibrated/20200827/ch2_ohr_ncp_20200827T0619368134_d_img_d18.img  \n",
            "   creating: /content/drive/MyDrive/unzipped_images/miscellaneous/\n",
            "   creating: /content/drive/MyDrive/unzipped_images/miscellaneous/calibrated/\n",
            "   creating: /content/drive/MyDrive/unzipped_images/miscellaneous/calibrated/20200827/\n",
            "  inflating: /content/drive/MyDrive/unzipped_images/miscellaneous/calibrated/20200827/ch2_ohr_ncp_20200827T0619368134_d_img_d18.oat  \n",
            "  inflating: /content/drive/MyDrive/unzipped_images/miscellaneous/calibrated/20200827/ch2_ohr_ncp_20200827T0619368134_d_img_d18.oath  \n",
            "  inflating: /content/drive/MyDrive/unzipped_images/miscellaneous/calibrated/20200827/ch2_ohr_ncp_20200827T0619368134_d_img_d18.lbr  \n",
            "  inflating: /content/drive/MyDrive/unzipped_images/miscellaneous/calibrated/20200827/ch2_ohr_ncp_20200827T0619368134_d_img_d18.spm  \n",
            "  inflating: /content/drive/MyDrive/unzipped_images/miscellaneous/readme.txt  \n",
            "   creating: /content/drive/MyDrive/unzipped_images/browse/\n",
            "   creating: /content/drive/MyDrive/unzipped_images/browse/calibrated/\n",
            "   creating: /content/drive/MyDrive/unzipped_images/browse/calibrated/20200827/\n",
            "  inflating: /content/drive/MyDrive/unzipped_images/browse/calibrated/20200827/ch2_ohr_ncp_20200827T0619368134_b_brw_d18.xml  \n",
            "  inflating: /content/drive/MyDrive/unzipped_images/browse/calibrated/20200827/ch2_ohr_ncp_20200827T0619368134_b_brw_d18.png  \n",
            "   creating: /content/drive/MyDrive/unzipped_images/geometry/\n",
            "   creating: /content/drive/MyDrive/unzipped_images/geometry/calibrated/\n",
            "   creating: /content/drive/MyDrive/unzipped_images/geometry/calibrated/20200827/\n",
            "  inflating: /content/drive/MyDrive/unzipped_images/geometry/calibrated/20200827/ch2_ohr_ncp_20200827T0619368134_g_grd_d18.xml  \n",
            "  inflating: /content/drive/MyDrive/unzipped_images/geometry/calibrated/20200827/ch2_ohr_ncp_20200827T0619368134_g_grd_d18.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEecYmOuv730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "02583b96-6ff9-40a0-d0b8-44689c4413c2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8dc9588cb7af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpds4_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pds4_tools'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "from scipy import signal\n",
        "from numpy.lib.stride_tricks import as_strided\n",
        "import cv2 \n",
        "import os\n",
        "from PIL import Image\n",
        "import pds4_tools\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import asarray\n",
        "from numpy import save"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def block_mean(ar, fact):\n",
        "    assert isinstance(fact, int), type(fact)\n",
        "    sx, sy = ar.shape\n",
        "    X, Y = np.ogrid[0:sx, 0:sy]\n",
        "    regions = sy//fact * (X//fact) + Y//fact\n",
        "    res = ndimage.mean(ar, labels=regions, index=np.arange(regions.max() + 1))\n",
        "    res.shape = (sx//fact, sy//fact)\n",
        "    return res\n",
        "\n",
        "def apply_to_slices(func, a, axes, fact,radius):\n",
        "  \"\"\"Apply 'func' to each slice of array 'a', where a slice spans 'axes'.\n",
        "\n",
        "  Args:\n",
        "    func: function expecting an array of rank len(axes) and returning a\n",
        "      modified array of the same shape.\n",
        "    a: input array of arbitrary shape.\n",
        "    axes: integer sequence specifying the slice orientation.\n",
        "  \"\"\"\n",
        "  # The approach is to move the slice axes to the end of the array, reshape to\n",
        "  # a 1-D array of slices, apply the user function to each slice, reshape back\n",
        "  # to an outer array of slices, and finally move the slice axes back to their\n",
        "  # original locations.  https://stackoverflow.com/a/61297133/\n",
        "  assert len(axes) <= a.ndim\n",
        "  outer_ndim = a.ndim - len(axes)\n",
        "  a = np.moveaxis(a, axes, range(outer_ndim, a.ndim))\n",
        "  outer_shape = a.shape[:outer_ndim]\n",
        "  slice_shape = a.shape[outer_ndim:]\n",
        "  a = a.reshape((-1,) + slice_shape)\n",
        "  a = np.array([func(a_slice, fact,radius) for a_slice in a])\n",
        "#   slice_shape[0] = slice_shape[0] // fact\n",
        "#   slice_shape[1] = slice_shape[1] // fact\n",
        "#   slice_shape1 = tuple(x // 2 for x in slice_shape)\n",
        "  slice_shape1 = tuple(x // fact for x in slice_shape)\n",
        "  a = a.reshape(outer_shape + slice_shape1)\n",
        "  a = np.moveaxis(a, range(outer_ndim, a.ndim), axes)\n",
        "  return a\n",
        "\n",
        "def downsample_avg(image, redn_fact, radius):\n",
        "    img_blur = ndimage.gaussian_filter(input = image, sigma = 0.3)\n",
        "    img_down = block_mean(img_blur, redn_fact)\n",
        "    return img_down\n",
        "\n",
        "def downsample_all_avg(img_set,redn_fact,radius):\n",
        "    img_set1=np.expand_dims(img_set,axis=3)\n",
        "    applied_samp=apply_to_slices(downsample_avg,img_set1,axes=(1,2),fact=redn_fact, radius = radius)\n",
        "    applied_samp=np.transpose(applied_samp,(0,3,1,2))\n",
        "    applied_samp = np.squeeze(applied_samp, axis = 1)\n",
        "    return applied_samp\n",
        "\n",
        "def conv2d(a, b, s=1):\n",
        "    Hout = (a.shape[1] - b.shape[0]) // s + 1\n",
        "    Wout = (a.shape[2] - b.shape[1]) // s + 1\n",
        "    Stride = (a.strides[0], a.strides[1] * s, a.strides[2] * s, a.strides[1], a.strides[2], a.strides[3])\n",
        "    a = as_strided(a, (a.shape[0], Hout, Wout, b.shape[0], b.shape[1], a.shape[3]), Stride)\n",
        "    return np.tensordot(a, b, axes=3)\n",
        "\n",
        "def downsample_decimate(image, redn_fact, radius):\n",
        "    image_blur = ndimage.gaussian_filter(input = image, sigma = 0.3)\n",
        "    image_blur = np.expand_dims(image_blur, axis = 0)\n",
        "    image_blur = np.expand_dims(image_blur, axis = 3)\n",
        "    weight = np.zeros(redn_fact * redn_fact).astype('int')\n",
        "    weight.shape = (redn_fact, redn_fact)\n",
        "    weight[0][0] = 1\n",
        "    weight = np.expand_dims(weight, axis = 2)\n",
        "    weight = np.expand_dims(weight, axis = 3)\n",
        "    stride = redn_fact\n",
        "    convolved = conv2d(image_blur, weight, stride)\n",
        "    convolved = np.squeeze(convolved, axis = 3)\n",
        "    convolved = np.squeeze(convolved, axis = 0)\n",
        "    return convolved\n",
        "\n",
        "def downsample_all_decimate(img_set,redn_fact,radius):\n",
        "    img_set1=np.expand_dims(img_set,axis=3)\n",
        "    applied_samp=apply_to_slices(downsample_decimate,img_set1,axes=(1,2),fact=redn_fact, radius = radius)\n",
        "    applied_samp=np.transpose(applied_samp,(0,3,1,2))\n",
        "    applied_samp = np.squeeze(applied_samp, axis = 1)\n",
        "    return applied_samp"
      ],
      "metadata": {
        "id": "fGYvQrKnwKLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_ohrc(path):\n",
        "    structure = pds4_tools.read(path)\n",
        "    temp = structure[0].data  # matrix with all the grayscale values\n",
        "    temp = np.array(temp)\n",
        "    return temp\n",
        "\n",
        "def reshape_split(image: np.ndarray, kernel_size: tuple):\n",
        "\n",
        "    img_height, img_width = image.shape\n",
        "    channels = 1\n",
        "    tile_height, tile_width = kernel_size\n",
        "\n",
        "    tiled_array = image.reshape(img_height // tile_height,\n",
        "                                tile_height,\n",
        "                                img_width // tile_width,\n",
        "                                tile_width,\n",
        "                                channels)\n",
        "    tiled_array = tiled_array.swapaxes(1, 2)\n",
        "    return tiled_array\n",
        "\n",
        "def tiles1(image, tile_X, tile_Y):\n",
        "    xtra_X = image.shape[0] - (image.shape[0] % tile_X)\n",
        "    xtra_Y = image.shape[1] - (image.shape[1] % tile_Y)\n",
        "    image = image[:xtra_X, :xtra_Y]\n",
        "    tiled_images = reshape_split(image, (tile_X, tile_Y))\n",
        "    tiled_images = np.squeeze(tiled_images, axis = 4)\n",
        "    tiled_images = np.reshape(tiled_images, (tiled_images.shape[0] * tiled_images.shape[1], tiled_images.shape[2], tiled_images.shape[3]))\n",
        "    return tiled_images"
      ],
      "metadata": {
        "id": "AGzrrWPDwXVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batchpasser(batch_size, tiled_images, redn_fact, radius, l):\n",
        "#     idx = new_idx\n",
        "    \n",
        "    frames = tiled_images.shape[0]\n",
        "    print(\"Creating Batches of Size:\", batch_size)\n",
        "    print(\"Total Batches found:\", frames // batch_size + 1)\n",
        "    for i in range(frames // batch_size + 1):\n",
        "        print(\"Processing Batch\", i + 1)\n",
        "        if(i * batch_size + batch_size > frames):\n",
        "            downsampled = downsample_all_decimate(tiled_images[i * batch_size : frames + 1, :, :], redn_fact, radius)\n",
        "            for j in range(downsampled.shape[0]):\n",
        "                if(redn_fact == 32):\n",
        "                    save(r\"C:\\Users\\acer\\OneDrive - Indian Institute of Technology Patna\\Desktop\\ISRO\\DownSampled\\LR\\\\\" + str(l[0]), downsampled[j])\n",
        "                    l[0] += 1\n",
        "                elif(redn_fact == 8):\n",
        "                    save(r\"C:\\Users\\acer\\OneDrive - Indian Institute of Technology Patna\\Desktop\\ISRO\\DownSampled\\HR\\\\\" + str(l[0]), downsampled[j])\n",
        "                    l[0] += 1\n",
        "            print(\"Saved Downsampled Images with Redn_Fact ({}), range({} to {})\".format(redn_fact, i * batch_size, frames))\n",
        "            break\n",
        "        downsampled = downsample_all_decimate(tiled_images[i * batch_size : i * batch_size + batch_size, :, :], redn_fact, radius)\n",
        "        for j in range(downsampled.shape[0]):\n",
        "            if(redn_fact == 32):\n",
        "                save(r\"C:\\Users\\acer\\OneDrive - Indian Institute of Technology Patna\\Desktop\\ISRO\\DownSampled\\LR\\\\\" + str(l[0]), downsampled[j])\n",
        "                l[0] += 1\n",
        "            elif(redn_fact == 8):\n",
        "                save(r\"C:\\Users\\acer\\OneDrive - Indian Institute of Technology Patna\\Desktop\\ISRO\\DownSampled\\HR\\\\\" + str(l[0]), downsampled[j])\n",
        "                l[0] += 1\n",
        "        print(\"Saved Downsampled Images with Redn_Fact ({}), range({} to {})\".format(redn_fact, i * batch_size, i * batch_size + batch_size - 1))\n",
        "            # image is downsampled[j] -> 2d image\n",
        "#     l[0] = idx"
      ],
      "metadata": {
        "id": "VvFrVwbZwYr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def access_OHRC(paths, tile_X, tile_Y, redn_fact, batch_size, radius):\n",
        "#     path where all OHRC folders are present is to be taken as i/p\n",
        "    rootdir = paths\n",
        "    directories = []\n",
        "    for file in os.listdir(rootdir):\n",
        "        d = os.path.join(rootdir, file)\n",
        "        if os.path.isdir(d):\n",
        "            final = os.path.join(d, r'data\\calibrated')\n",
        "            for inside in os.listdir(final):\n",
        "                direc = os.path.join(final, inside)\n",
        "                for insider in os.listdir(direc):\n",
        "                    if(insider[-3:] == \"xml\"):\n",
        "                        direc = os.path.join(direc, insider)\n",
        "                        directories.append(direc)\n",
        "                        break\n",
        "    l = [0]\n",
        "    for direc in directories:\n",
        "        print(\"Accessing directory:\", direc)\n",
        "        image = read_ohrc(direc)\n",
        "        print(\"Image_Size =\", image.shape[0], image.shape[1])\n",
        "        print(\"Tiling Image with Tile_Size:\", tile_X, tile_Y)\n",
        "        tiled_image = tiles1(image, tile_X * redn_fact, tile_Y * redn_fact)\n",
        "        print(\"Image Tiled... Total tiles found:\", tiled_image.shape[0])\n",
        "        print(\"Preparing Tiles for BatchPassing to DownSampler...\")\n",
        "        print(\"current_idx:\", l[0])\n",
        "        batchpasser(batch_size, tiled_image, redn_fact, radius, l)\n",
        "#         del image\n",
        "#         del tiled_image"
      ],
      "metadata": {
        "id": "xejaZxbywb53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "access_OHRC(r\"C:\\Users\\acer\\OneDrive - Indian Institute of Technology Patna\\Desktop\\ISRO\\Data\\\\\", 80, 80, 32, 4, 3)"
      ],
      "metadata": {
        "id": "-w85Abw8wdoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "access_OHRC(r\"C:\\Users\\acer\\OneDrive - Indian Institute of Technology Patna\\Desktop\\ISRO\\Data\\\\\", 80, 80, 8, 4, 3)"
      ],
      "metadata": {
        "id": "Bm5NidzOwedG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CRMchhRSwv5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893f32e0-2ce5-4073-a9ee-9cc3b1a98c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}